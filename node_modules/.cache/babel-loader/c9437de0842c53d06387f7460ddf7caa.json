{"ast":null,"code":"function g() {\n  return (g = Object.assign || function (a) {\n    var d, e, b;\n\n    for (d = 1; d < arguments.length; d++) {\n      e = arguments[d];\n\n      for (b in e) {\n        Object.prototype.hasOwnProperty.call(e, b) && (a[b] = e[b]);\n      }\n    }\n\n    return a;\n  }).apply(this, arguments);\n}\n\nfunction m(a) {\n  return a && a.networkError;\n}\n\nimport { makeOperation } from \"@urql/core\";\nimport { share, makeSubject, mergeMap, filter, takeUntil, delay, fromValue, merge } from \"wonka\";\nexport function retryExchange(a) {\n  var d = a.initialDelayMs || 1e3,\n      e = a.maxDelayMs || 15e3,\n      b = a.maxNumberAttempts || 2,\n      n = a.randomDelay || !0,\n      p = a.retryIf || m;\n  return function (a) {\n    var q = a.forward,\n        k = a.dispatchDebug;\n    return function (a) {\n      var r,\n          t,\n          l = share(a);\n      r = (a = makeSubject()).source, t = a.next;\n      a = mergeMap(function (a) {\n        var f,\n            u = a.key,\n            c = a.context,\n            h = (c.retryCount || 0) + 1;\n        c = c.retryDelay || d;\n        f = Math.random() + 1.5;\n        n && c * f < e && (c *= f);\n        f = filter(function (a) {\n          return (\"query\" === a.kind || \"teardown\" === a.kind) && a.key === u;\n        })(l);\n        \"production\" !== process.env.NODE_ENV && k({\n          type: \"retryAttempt\",\n          message: \"The operation has failed and a retry has been triggered (\" + h + \" / \" + b + \")\",\n          operation: a,\n          data: {\n            retryCount: h\n          },\n          source: \"retryExchange\"\n        });\n        return takeUntil(f)(delay(c)(fromValue(makeOperation(a.kind, a, g({}, a.context, {\n          retryDelay: c,\n          retryCount: h\n        })))));\n      })(r);\n      return filter(function (a) {\n        if (!a.error || !p(a.error, a.operation)) {\n          return !0;\n        }\n\n        if (!((a.operation.context.retryCount || 0) >= b - 1)) {\n          return t(a.operation), !1;\n        }\n\n        \"production\" !== process.env.NODE_ENV && k({\n          type: \"retryExhausted\",\n          message: \"Maximum number of retries has been reached. No further retries will be performed.\",\n          operation: a.operation,\n          source: \"retryExchange\"\n        });\n        return !0;\n      })(share(q(merge([l, a]))));\n    };\n  };\n}","map":{"version":3,"sources":["../src/retryExchange.ts"],"names":["share","retryWithBackoff$","mergeMap","context","backoffFactor","delayAmount","filter","merge","res","u","nextRetryOperation","Math"],"mappings":";;;;;;;;;;;;;;;;;cA6CkCA,CAAAA,CAAAA,Y;;;;;OAKxBC,SAAAA,aAAAA,CAAAA,CAAAA,EAAAA;;YAKgBE,U,IAAAA,I;MAAAA,CAAAA,GAAAA,CAAAA,CAEZC,iBAFYD,IAEZC,C;MAAAA,CAAAA,GAAAA,CAAAA,CAAAA,WAAAA,IAAAA,CAIJC,C;MAAAA,CAAAA,GAAAA,CAAAA,CAQAC,OARAD,IAQAC,C;;YAAAA,CAAAA,CAAAA,O;QAAAA,CAAAA,GAAAA,CAAAA,CAAAA,a;;;;UAjBJJ,CAAAA,GAAAA,KAAAA,CAAAA,CAAAA,C;;;;YA+DMO,CAAAA,GAFDD,CAAAA,CAAAA,G;YAAAA,CAAAA,GAAAA,CAAAA,CAKDE,O;YAAAA,CAAAA,GAAAA,CAAAA,CAAAA,CAAAA,UAAAA,IAAAA,CAAAA,IAAAA,C;;YAWKC,IAAAA,CAAAA,MAAAA,KAAAA,G;AAxBTL,QAAAA,CAAAA,IAAAA,CAAAA,GAHAC,CAGAD,GAHAC,CAGAD,KAHmBL,CAAAA,IAGnBK,CAAAA","sourcesContent":["import {\n  makeSubject,\n  share,\n  pipe,\n  merge,\n  filter,\n  fromValue,\n  delay,\n  mergeMap,\n  takeUntil,\n} from 'wonka';\nimport {\n  makeOperation,\n  Exchange,\n  Operation,\n  CombinedError,\n  OperationResult,\n} from '@urql/core';\nimport { sourceT } from 'wonka/dist/types/src/Wonka_types.gen';\n\ninterface RetryExchangeOptions {\n  initialDelayMs?: number;\n  maxDelayMs?: number;\n  randomDelay?: boolean;\n  maxNumberAttempts?: number;\n  /** Conditionally determine whether an error should be retried */\n  retryIf?: (error: CombinedError, operation: Operation) => boolean;\n}\n\nexport const retryExchange = ({\n  initialDelayMs,\n  maxDelayMs,\n  randomDelay,\n  maxNumberAttempts,\n  retryIf: retryIfOption,\n}: RetryExchangeOptions): Exchange => {\n  const MIN_DELAY = initialDelayMs || 1000;\n  const MAX_DELAY = maxDelayMs || 15000;\n  const MAX_ATTEMPTS = maxNumberAttempts || 2;\n  const RANDOM_DELAY = randomDelay || true;\n\n  const retryIf =\n    retryIfOption || ((err: CombinedError) => err && err.networkError);\n\n  return ({ forward, dispatchDebug }) => ops$ => {\n    const sharedOps$ = pipe(ops$, share);\n    const { source: retry$, next: nextRetryOperation } = makeSubject<\n      Operation\n    >();\n\n    const retryWithBackoff$ = pipe(\n      retry$,\n      mergeMap((op: Operation) => {\n        const { key, context } = op;\n        const retryCount = (context.retryCount || 0) + 1;\n        let delayAmount = context.retryDelay || MIN_DELAY;\n\n        const backoffFactor = Math.random() + 1.5;\n        // if randomDelay is enabled and it won't exceed the max delay, apply a random\n        // amount to the delay to avoid thundering herd problem\n        if (RANDOM_DELAY && delayAmount * backoffFactor < MAX_DELAY) {\n          delayAmount *= backoffFactor;\n        }\n\n        // We stop the retries if a teardown event for this operation comes in\n        // But if this event comes through regularly we also stop the retries, since it's\n        // basically the query retrying itself, no backoff should be added!\n        const teardown$ = pipe(\n          sharedOps$,\n          filter(op => {\n            return (\n              (op.kind === 'query' || op.kind === 'teardown') && op.key === key\n            );\n          })\n        );\n\n        dispatchDebug({\n          type: 'retryAttempt',\n          message: `The operation has failed and a retry has been triggered (${retryCount} / ${MAX_ATTEMPTS})`,\n          operation: op,\n          data: {\n            retryCount,\n          },\n        });\n\n        // Add new retryDelay and retryCount to operation\n        return pipe(\n          fromValue(\n            makeOperation(op.kind, op, {\n              ...op.context,\n              retryDelay: delayAmount,\n              retryCount,\n            })\n          ),\n          delay(delayAmount),\n          // Stop retry if a teardown comes in\n          takeUntil(teardown$)\n        );\n      })\n    );\n\n    const result$ = pipe(\n      merge([sharedOps$, retryWithBackoff$]),\n      forward,\n      share,\n      filter(res => {\n        // Only retry if the error passes the conditional retryIf function (if passed)\n        // or if the error contains a networkError\n        if (!res.error || !retryIf(res.error, res.operation)) {\n          return true;\n        }\n\n        const maxNumberAttemptsExceeded =\n          (res.operation.context.retryCount || 0) >= MAX_ATTEMPTS - 1;\n\n        if (!maxNumberAttemptsExceeded) {\n          // Send failed responses to be retried by calling next on the retry$ subject\n          // Exclude operations that have been retried more than the specified max\n          nextRetryOperation(res.operation);\n          return false;\n        }\n\n        dispatchDebug({\n          type: 'retryExhausted',\n          message:\n            'Maximum number of retries has been reached. No further retries will be performed.',\n          operation: res.operation,\n        });\n\n        return true;\n      })\n    ) as sourceT<OperationResult>;\n\n    return result$;\n  };\n};\n"]},"metadata":{},"sourceType":"module"}